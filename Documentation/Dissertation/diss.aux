\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plain}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{diss.ist}
\@glsorder{word}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Terminology and preliminary definitions}{1}{section.1.1}}
\newlabel{sec:term_and_def}{{1.1}{1}{Terminology and preliminary definitions}{section.1.1}{}}
\citation{Qingli:2013:spectralImagingTech}
\citation{Bioucas-Dias:2012:unmixingOverview}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of (a) a time-domain signal $f(t)$, (b) it's Fourier transform $F(\omega )$, (c) it's power spectrum $|F(\omega )|^2$ and (d) a quantisation of c.\relax }}{2}{figure.caption.11}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:spectrum}{{1.1}{2}{Examples of (a) a time-domain signal $f(t)$, (b) it's Fourier transform $F(\omega )$, (c) it's power spectrum $|F(\omega )|^2$ and (d) a quantisation of c.\relax }{figure.caption.11}{}}
\citation{Luthman:2015:hyperspectralImager}
\citation{Bioucas-Dias:2012:unmixingOverview}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Examples of a monochrome image (left) and a spectral image (right).\relax }}{3}{figure.caption.12}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}What are we trying to do?}{3}{section.1.2}}
\newlabel{sec:what_are_we_trying_to_do}{{1.2}{3}{What are we trying to do?}{section.1.2}{}}
\citation{Luthman:2015:hyperspectralImager}
\citation{keshava2003survey}
\citation{Luthman:2015:hyperspectralImager}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Possible solutions}{4}{section.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Related work}{4}{section.1.4}}
\citation{pham2000current}
\citation{criminisi2013decision}
\citation{zhao2016segmenting}
\citation{zhao2016multiscale}
\citation{conjeti2016supervised}
\citation{criminisi2012decision}
\citation{badrinarayanan2015segnet2}
\citation{jia2014caffe}
\citation{klein2004lagrange}
\citation{law2006simple}
\citation{seymore1999learning}
\citation{cunningham2007k}
\citation{criminisi2013decision}
\citation{heaton2008introduction}
\citation{JMLR:v16:heaton15a}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preparation}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}An introduction to image segmentation}{7}{section.2.1}}
\citation{PAL19931277}
\citation{PAL19931277}
\citation{PAL19931277}
\citation{russell1995modern}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Supervised learning for classification}{8}{section.2.2}}
\newlabel{sec:supervised_learning}{{2.2}{8}{Supervised learning for classification}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Decision trees and random forests}{9}{section.2.3}}
\newlabel{sec:rand_forest}{{2.3}{9}{Decision trees and random forests}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Introduction to decision trees}{9}{subsection.2.3.1}}
\newlabel{sec:intro_decision_trees}{{2.3.1}{9}{Introduction to decision trees}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of (part of) a tree used to classify humans.\relax }}{10}{figure.caption.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of node numberings in a decision tree.\relax }}{10}{figure.caption.14}}
\citation{criminisi2013decision}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of how some instance $\mathbf  {x}$ would be classified using a decision tree.\relax }}{11}{figure.caption.15}}
\newlabel{fig:decision_tree_classify}{{2.3}{11}{Example of how some instance $\vc {x}$ would be classified using a decision tree.\relax }{figure.caption.15}{}}
\citation{criminisi2013decision}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Training a decision tree}{12}{subsection.2.3.2}}
\newlabel{eq:training_seq_entropy}{{2.7}{12}{Training a decision tree}{equation.2.3.7}{}}
\newlabel{eq:empirical_distribution}{{2.8}{12}{Training a decision tree}{equation.2.3.8}{}}
\newlabel{eq:left_split}{{2.9}{12}{Training a decision tree}{equation.2.3.9}{}}
\newlabel{eq:right_split}{{2.10}{12}{Training a decision tree}{equation.2.3.10}{}}
\newlabel{eq:information_gain}{{2.11}{12}{Training a decision tree}{equation.2.3.11}{}}
\citation{criminisi2013decision}
\citation{criminisi2013decision}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Moving swiftly on to random forests}{13}{subsection.2.3.3}}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Neural Networks}{14}{section.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Imaging and image noise}{14}{section.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Image sensor arrays}{14}{subsection.2.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces CCD and CMOS sensor arrays. Reproduced from Gamel et al \cite  {gamal2005cmos}.\relax }}{14}{figure.caption.16}}
\newlabel{fig:image_pipeline}{{2.4}{14}{CCD and CMOS sensor arrays. Reproduced from Gamel et al \cite {gamal2005cmos}.\relax }{figure.caption.16}{}}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Overview of an imaging `pipeline'. Reproduced from Gamel et al \cite  {gamal2005cmos}.\relax }}{15}{figure.caption.17}}
\newlabel{fig:image_pipeline}{{2.5}{15}{Overview of an imaging `pipeline'. Reproduced from Gamel et al \cite {gamal2005cmos}.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Parallel stream of photons incident on one sensor in a sensor array.\relax }}{15}{figure.caption.18}}
\newlabel{fig:photon_stream}{{2.6}{15}{Parallel stream of photons incident on one sensor in a sensor array.\relax }{figure.caption.18}{}}
\citation{hasinoff2014photon}
\citation{ross2002probability}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces The charge held on a capacitor is linear with respect time, until it hits some maximum \cite  {gamal2005cmos}.\relax }}{16}{figure.caption.19}}
\newlabel{fig:linear_charge_wrt_photon_rate}{{2.7}{16}{The charge held on a capacitor is linear with respect time, until it hits some maximum \cite {gamal2005cmos}.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Quantum noise}{16}{subsection.2.5.2}}
\newlabel{eq:image_poisson}{{2.20}{16}{Quantum noise}{equation.2.5.20}{}}
\citation{picano2004sustainability}
\citation{sprawls1987physical}
\citation{coupe2009nonlocal}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of Poisson($\mu $) and SPoisson($\mu $, 30) distributions, for $\mu = 5,15,25$.\relax }}{18}{figure.caption.20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Additive White Gaussian Noise}{18}{subsection.2.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Medical imaging noise}{18}{subsection.2.5.4}}
\citation{figueiredo2006total}
\citation{rodrigues2008denoising}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}TVMM Image De-Noising}{19}{section.2.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Requirements analysis}{19}{section.2.7}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces High level goals and desired outcomes for the project.\relax }}{19}{table.caption.21}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}System Design}{20}{section.2.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Pipeline/Overview}{20}{subsection.2.8.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Overview of the system and its intended use.\relax }}{20}{figure.caption.22}}
\newlabel{fig:system_overview}{{2.9}{20}{Overview of the system and its intended use.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Interface/Usage}{20}{subsection.2.8.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2.1}Training Tools}{21}{subsubsection.2.8.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Overview of the training tools function.\relax }}{21}{figure.caption.23}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2.2}Train}{21}{subsubsection.2.8.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Overview of the train function.\relax }}{22}{figure.caption.24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2.3}Learn From Example}{22}{subsubsection.2.8.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Overview of the learn from example function.\relax }}{22}{figure.caption.25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2.4}Pixel Labeller}{22}{subsubsection.2.8.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Overview of the pixel labeller function.\relax }}{23}{figure.caption.26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2.5}De-Noiser}{23}{subsubsection.2.8.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Overview of the de-noiser function.\relax }}{23}{figure.caption.27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2.6}Noisy Pixel Labeller}{23}{subsubsection.2.8.2.6}}
\citation{JMLR:v16:heaton15a}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Overview of the noisy pixel labeller function.\relax }}{24}{figure.caption.28}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Languages and tools}{24}{section.2.9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Software engineering techniques}{25}{section.2.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.1}Development model}{25}{subsection.2.10.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.2}Testing}{26}{subsection.2.10.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.3}Backup Plan}{26}{subsection.2.10.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Overview of the backup strategy employed.}}{27}{figure.caption.29}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Implementation}{29}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The dependencies between different packages/modules in the system. Although TrainingTools package is capable of producing training sequence files both the NeuralNetworks and RandomDecisionForests, it only \textit  {depends} on RandomDecisionForests as it uses the class \texttt  {TrainingSequence}.\relax }}{30}{figure.caption.30}}
\newlabel{fig:package_dependencies}{{3.1}{30}{The dependencies between different packages/modules in the system. Although TrainingTools package is capable of producing training sequence files both the NeuralNetworks and RandomDecisionForests, it only \textit {depends} on RandomDecisionForests as it uses the class \texttt {TrainingSequence}.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Random Forests Library}{30}{section.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An overview of classes in the RandomDecisionForest package.\relax }}{31}{figure.caption.31}}
\newlabel{fig:forest_uml}{{3.2}{31}{An overview of classes in the RandomDecisionForest package.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Data structures}{32}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.1}ClassLabels}{32}{subsubsection.3.1.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces \texttt  {ClassLabel} in figure \ref  {fig:forest_uml} a bit closer.\relax }}{32}{figure.caption.32}}
\newlabel{fig:class_label_uml}{{3.3}{32}{\texttt {ClassLabel} in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Important methods implemented in the \texttt  {ClassLabel} class.\relax }}{33}{table.caption.33}}
\newlabel{tab:ClassLabel}{{3.1}{33}{Important methods implemented in the \texttt {ClassLabel} class.\relax }{table.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.2}Instances}{33}{subsubsection.3.1.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces \texttt  {Instance} in figure \ref  {fig:forest_uml} a bit closer.\relax }}{34}{figure.caption.34}}
\newlabel{fig:instance_uml}{{3.4}{34}{\texttt {Instance} in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.34}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Important methods implemented in the \texttt  {NDRealVector} class.\relax }}{35}{table.caption.35}}
\newlabel{tab:NDRealVector}{{3.2}{35}{Important methods implemented in the \texttt {NDRealVector} class.\relax }{table.caption.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.3}Probability Distributions}{35}{subsubsection.3.1.1.3}}
\newlabel{sec:prob_dist}{{3.1.1.3}{35}{Probability Distributions}{subsubsection.3.1.1.3}{}}
\newlabel{eq:prob_entropy}{{3.1}{35}{Probability Distributions}{equation.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces \texttt  {ProbabilityDistribution} in figure \ref  {fig:forest_uml} a bit closer.\relax }}{36}{figure.caption.36}}
\newlabel{fig:prob_dist_uml}{{3.5}{36}{\texttt {ProbabilityDistribution} in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.36}{}}
\citation{1985--ieee754}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}Part of the \texttt  {ProbabilityDirstribution} constructor, where we set $\epsilon = 2^{-10}$.}{37}{lstlisting.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Important methods implemented in the \texttt  {ProbabilityDistribution} class.\relax }}{38}{table.caption.37}}
\newlabel{tab:ProbabilityDistribution}{{3.3}{38}{Important methods implemented in the \texttt {ProbabilityDistribution} class.\relax }{table.caption.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.4}Training Sequences}{38}{subsubsection.3.1.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces \texttt  {TrainingSequence} and \texttt  {TrainingSample} in figure \ref  {fig:forest_uml} a bit closer.\relax }}{39}{figure.caption.38}}
\newlabel{fig:training_seq_uml}{{3.6}{39}{\texttt {TrainingSequence} and \texttt {TrainingSample} in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.38}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Member functions of the \texttt  {TrainingSequence} class.\relax }}{40}{table.caption.39}}
\newlabel{tab:TrainingSequence}{{3.4}{40}{Member functions of the \texttt {TrainingSequence} class.\relax }{table.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.5}Split Parameters}{41}{subsubsection.3.1.1.5}}
\newlabel{sec:split_params}{{3.1.1.5}{41}{Split Parameters}{subsubsection.3.1.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces \texttt  {SplitParamter} and \texttt  {OneDimensionalLinearSplitParameter} in figure \ref  {fig:forest_uml} a bit closer.\relax }}{41}{figure.caption.40}}
\newlabel{fig:split_param_uml}{{3.7}{41}{\texttt {SplitParamter} and \texttt {OneDimensionalLinearSplitParameter} in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.6}Weak Learners}{42}{subsubsection.3.1.1.6}}
\newlabel{sec:weak_learner}{{3.1.1.6}{42}{Weak Learners}{subsubsection.3.1.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The \texttt  {WeakLearnerType} enum in figure \ref  {fig:forest_uml} a bit closer.\relax }}{42}{figure.caption.41}}
\newlabel{fig:weak_learner_type_uml}{{3.8}{42}{The \texttt {WeakLearnerType} enum in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.41}{}}
\newlabel{eq:split_equation}{{3.10}{43}{Weak Learners}{equation.3.1.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces \texttt  {WeakLearner} and \texttt  {OneDimensionalLinearWeakLearner} in figure \ref  {fig:forest_uml} a bit closer.\relax }}{43}{figure.caption.42}}
\newlabel{fig:weak_learner_uml}{{3.9}{43}{\texttt {WeakLearner} and \texttt {OneDimensionalLinearWeakLearner} in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Member functions of the \texttt  {OneDimensionalLinearWeakLearner} class.\relax }}{44}{table.caption.43}}
\newlabel{tab:OneDimensionalLinearWeakLearner}{{3.5}{44}{Member functions of the \texttt {OneDimensionalLinearWeakLearner} class.\relax }{table.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Knowing the minimum and maximum values in each dimension allows us to make an informed choice on split parameters to pick, which in this case is the green zone of values.\relax }}{45}{figure.caption.44}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.7}Decision Tree Node}{45}{subsubsection.3.1.1.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces \texttt  {TreeNode} and \texttt  {DecisionForest} in figure \ref  {fig:forest_uml} a bit closer.\relax }}{46}{figure.caption.45}}
\newlabel{fig:weak_learner_uml}{{3.11}{46}{\texttt {TreeNode} and \texttt {DecisionForest} in figure \ref {fig:forest_uml} a bit closer.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces An example of how \texttt  {compact} could be used to reduce the size of a decision tree.\relax }}{47}{figure.caption.46}}
\newlabel{lst:TreeNode}{{3.2}{47}{The \texttt {TreeNode} declaration, found as a static class within the \texttt {DecisionForest} class}{lstlisting.3.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}The \texttt  {TreeNode} declaration, found as a static class within the \texttt  {DecisionForest} class.}{47}{lstlisting.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Member functions of the \texttt  {TreeNode} class.\relax }}{48}{table.caption.47}}
\newlabel{tab:TreeNode}{{3.6}{48}{Member functions of the \texttt {TreeNode} class.\relax }{table.caption.47}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.8}Decision Forest}{48}{subsubsection.3.1.1.8}}
\newlabel{sec:DecisionForest}{{3.1.1.8}{48}{Decision Forest}{subsubsection.3.1.1.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Member functions of the \texttt  {TreeNode} class.\relax }}{49}{table.caption.48}}
\newlabel{tab:DecisionForest}{{3.7}{49}{Member functions of the \texttt {TreeNode} class.\relax }{table.caption.48}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Training}{49}{subsection.3.1.2}}
\newlabel{sec:training}{{3.1.2}{49}{Training}{subsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Classification}{49}{subsection.3.1.3}}
\newlabel{sec:classification}{{3.1.3}{49}{Classification}{subsection.3.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Neural Networks}{50}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Training}{50}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Classification}{50}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Pixel Labelling}{50}{section.3.3}}
\newlabel{sec:pixel_label}{{3.3}{50}{Pixel Labelling}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training Tools}{51}{section.3.4}}
\newlabel{sec:training_tools}{{3.4}{51}{Training Tools}{section.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}De-noising}{51}{section.3.5}}
\newlabel{sec:de-noising}{{3.5}{51}{De-noising}{section.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Application on example data sets}{51}{section.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Siri's data}{51}{subsection.3.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Teng's data}{51}{subsection.3.6.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation}{53}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Performance measures for classifiers}{53}{section.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Evaluation of Random Forests pixel labelling}{53}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Evaluation of Neural Networks pixel labelling}{53}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Evaluation of the Random Forests library}{54}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Training time}{54}{subsection.4.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Classification time}{54}{subsection.4.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}The effect of the number of trees}{54}{subsection.4.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}The effect of the depth of trees}{54}{subsection.4.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}The effect of the randomness of trees}{54}{subsection.4.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}The effect of normalisation}{54}{subsection.4.4.6}}
\newlabel{sec:effect_of_normalisation}{{4.4.6}{54}{The effect of normalisation}{subsection.4.4.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}The effect of the de-noising component}{54}{section.4.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{55}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Summary}{55}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Further Work}{55}{section.5.2}}
\bibdata{refs}
\bibcite{1985--ieee754}{1}
\bibcite{badrinarayanan2015segnet2}{2}
\bibcite{Bioucas-Dias:2012:unmixingOverview}{3}
\bibcite{conjeti2016supervised}{4}
\bibcite{coupe2009nonlocal}{5}
\bibcite{criminisi2013decision}{6}
\bibcite{criminisi2012decision}{7}
\bibcite{cunningham2007k}{8}
\bibcite{figueiredo2006total}{9}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{57}{section.5.2}}
\bibcite{gamal2005cmos}{10}
\bibcite{hasinoff2014photon}{11}
\bibcite{heaton2008introduction}{12}
\bibcite{JMLR:v16:heaton15a}{13}
\bibcite{jia2014caffe}{14}
\bibcite{keshava2003survey}{15}
\bibcite{klein2004lagrange}{16}
\bibcite{law2006simple}{17}
\bibcite{Qingli:2013:spectralImagingTech}{18}
\bibcite{Luthman:2015:hyperspectralImager}{19}
\bibcite{PAL19931277}{20}
\bibcite{pham2000current}{21}
\bibcite{picano2004sustainability}{22}
\bibcite{rodrigues2008denoising}{23}
\bibcite{ross2002probability}{24}
\bibcite{russell1995modern}{25}
\bibcite{seymore1999learning}{26}
\bibcite{sprawls1987physical}{27}
\bibcite{zhao2016segmenting}{28}
\bibcite{zhao2016multiscale}{29}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}File formats}{61}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:file_formats}{{A}{61}{File formats}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}(Example/Noisy) Spectral Image}{61}{section.A.1}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Example Image Labelling}{61}{section.A.2}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Label Map}{61}{section.A.3}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Training Sequence}{61}{section.A.4}}
\@writefile{toc}{\contentsline {section}{\numberline {A.5}Output Files}{62}{section.A.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}A brief explanation of the method of conjugate gradients}{63}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Project Proposal}{65}{appendix.C}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Glossary}{77}{appendix.D}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
