\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plain}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{diss.ist}
\@glsorder{word}
\citation{gamal2005cmos}
\citation{Qingli:2013:spectralImagingTech}
\citation{Bioucas-Dias:2012:unmixingOverview}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Terminology and preliminary definitions}{1}{section.1.1}}
\newlabel{sec:term_and_def}{{1.1}{1}{Terminology and preliminary definitions}{section.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of (a) a time-domain signal $f(t)$, (b) it's Fourier transform $F(\omega )$, (c) it's power spectrum $|F(\omega )|^2$ and (d) a quantisation of c.\relax }}{2}{figure.caption.11}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:spectrum}{{1.1}{2}{Examples of (a) a time-domain signal $f(t)$, (b) it's Fourier transform $F(\omega )$, (c) it's power spectrum $|F(\omega )|^2$ and (d) a quantisation of c.\relax }{figure.caption.11}{}}
\citation{Luthman:2015:hyperspectralImager}
\citation{Bioucas-Dias:2012:unmixingOverview}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Examples of a monochrome image (left) and a spectral image (right).\relax }}{3}{figure.caption.12}}
\citation{Luthman:2015:hyperspectralImager}
\citation{Luthman:2015:hyperspectralImager}
\citation{keshava2003survey}
\citation{Luthman:2015:hyperspectralImager}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Aims of the project}{4}{section.1.2}}
\newlabel{sec:what_are_we_trying_to_do}{{1.2}{4}{Aims of the project}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Possible solutions}{4}{section.1.3}}
\citation{pham2000current}
\citation{criminisi2013decision}
\citation{zhao2016segmenting}
\citation{zhao2016multiscale}
\citation{conjeti2016supervised}
\citation{criminisi2012decision}
\citation{badrinarayanan2015segnet2}
\citation{jia2014caffe}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Related work}{5}{section.1.4}}
\citation{klein2004lagrange}
\citation{law2006simple}
\citation{seymore1999learning}
\citation{cunningham2007k}
\citation{criminisi2013decision}
\citation{heaton2008introduction}
\citation{JMLR:v16:heaton15a}
\citation{PAL19931277}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preparation}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}An introduction to image segmentation}{7}{section.2.1}}
\citation{PAL19931277}
\citation{PAL19931277}
\citation{russell1995modern}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Supervised learning for classification}{8}{section.2.2}}
\newlabel{sec:supervised_learning}{{2.2}{8}{Supervised learning for classification}{section.2.2}{}}
\newlabel{eq:max_likelihood}{{2.3}{8}{Supervised learning for classification}{equation.2.2.3}{}}
\newlabel{eq:max_a_posteriori}{{2.4}{8}{Supervised learning for classification}{equation.2.2.4}{}}
\citation{criminisi2012decision}
\citation{criminisi2012decision}
\newlabel{eq:weird_hyp}{{2.5}{9}{Supervised learning for classification}{equation.2.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Decision trees and random forests}{9}{section.2.3}}
\newlabel{sec:rand_forest}{{2.3}{9}{Decision trees and random forests}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Introduction to decision trees}{9}{subsection.2.3.1}}
\newlabel{sec:intro_decision_trees}{{2.3.1}{9}{Introduction to decision trees}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of (part of) a tree used to classify humans.\relax }}{10}{figure.caption.13}}
\newlabel{fig:intuitive_tree}{{2.1}{10}{Example of (part of) a tree used to classify humans.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of node numberings in a decision tree.}}{10}{figure.caption.14}}
\citation{criminisi2013decision}
\citation{criminisi2012decision}
\citation{criminisi2012decision}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of how some instance $\mathbf  {v}$ would be classified using a decision tree.}}{11}{figure.caption.15}}
\newlabel{fig:decision_tree_classify}{{2.3}{11}{Example of how some instance $\vc {v}$ would be classified using a decision tree}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Training a decision tree}{11}{subsection.2.3.2}}
\citation{criminisi2013decision}
\citation{criminisi2013decision}
\newlabel{eq:training_seq_entropy}{{2.7}{12}{Training a decision tree}{equation.2.3.7}{}}
\newlabel{eq:empirical_distribution}{{2.8}{12}{Training a decision tree}{equation.2.3.8}{}}
\newlabel{eq:left_split}{{2.9}{12}{Training a decision tree}{equation.2.3.9}{}}
\newlabel{eq:right_split}{{2.10}{12}{Training a decision tree}{equation.2.3.10}{}}
\newlabel{eq:information_gain}{{2.11}{12}{Training a decision tree}{equation.2.3.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Moving swiftly on to random forests}{12}{subsection.2.3.3}}
\newlabel{sec:moving_swiftly_onto_forests}{{2.3.3}{12}{Moving swiftly on to random forests}{subsection.2.3.3}{}}
\citation{criminisi2013decision}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Neural networks}{13}{section.2.4}}
\newlabel{sec:neuralnetworkdef}{{2.4}{13}{Neural networks}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Neural network definitions}{13}{subsection.2.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of an (artificial) neuron, with 3 inputs.\relax }}{14}{figure.caption.16}}
\newlabel{fig:neuron}{{2.4}{14}{Example of an (artificial) neuron, with 3 inputs.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Training a neural network}{14}{subsection.2.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Example of a feed forward neural network.\relax }}{15}{figure.caption.17}}
\newlabel{fig:neuron}{{2.5}{15}{Example of a feed forward neural network.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A neural network showing internal values.}}{15}{figure.caption.18}}
\newlabel{fig:feedforwardNetwork}{{2.6}{15}{A neural network showing internal values}{figure.caption.18}{}}
\citation{russell1995modern}
\citation{eq:max_likelihood}
\citation{russell1995modern}
\citation{shewchuk1994introduction}
\citation{russell1995modern}
\newlabel{eq:optimisation}{{2.21}{16}{Training a neural network}{equation.2.4.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Requirements analysis}{16}{section.2.5}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces High level goals and desired outcomes for the project.\relax }}{17}{table.caption.19}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}System Design}{17}{section.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Pipeline/Overview}{17}{subsection.2.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Overview of the system and its intended use.\relax }}{18}{figure.caption.20}}
\newlabel{fig:system_overview}{{2.7}{18}{Overview of the system and its intended use.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Interface/Usage}{18}{subsection.2.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.1}Training Tools}{18}{subsubsection.2.6.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Overview of the training tools function.\relax }}{19}{figure.caption.21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.2}Train}{19}{subsubsection.2.6.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Overview of the train function.\relax }}{19}{figure.caption.22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.3}Learn From Example}{19}{subsubsection.2.6.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Overview of the \textit  {learn from example} function.\relax }}{20}{figure.caption.23}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.4}Pixel Labeller}{20}{subsubsection.2.6.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Overview of the pixel labeller function.\relax }}{20}{figure.caption.24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.5}De-Noiser}{21}{subsubsection.2.6.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Overview of the de-noiser function.\relax }}{21}{figure.caption.25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.6}Noisy Pixel Labeller}{21}{subsubsection.2.6.2.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Overview of the noisy pixel labeller function.\relax }}{21}{figure.caption.26}}
\citation{JMLR:v16:heaton15a}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Languages and tools}{22}{section.2.7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Software engineering techniques}{23}{section.2.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Development model}{23}{subsection.2.8.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Testing}{23}{subsection.2.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.3}Backup Plan}{24}{subsection.2.8.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Overview of the backup strategy employed.}}{25}{figure.caption.27}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Implementation}{27}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The dependencies between different packages/modules defined in the system.}}{28}{figure.caption.28}}
\newlabel{fig:package_dependencies}{{3.1}{28}{The dependencies between different packages/modules defined in the system}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Random Forests Library}{28}{section.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An overview of classes in the RandomDecisionForest package}}{29}{figure.caption.29}}
\newlabel{fig:forest_uml}{{3.2}{29}{An overview of classes in the RandomDecisionForest package}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Data structures}{30}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.1}ClassLabels}{30}{subsubsection.3.1.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A closer view of \texttt  {ClassLabel}}}{30}{figure.caption.30}}
\newlabel{fig:class_label_uml}{{3.3}{30}{A closer view of \texttt {ClassLabel}}{figure.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Important methods implemented in the \texttt  {ClassLabel} class.\relax }}{31}{table.caption.31}}
\newlabel{tab:ClassLabel}{{3.1}{31}{Important methods implemented in the \texttt {ClassLabel} class.\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.2}Instances}{31}{subsubsection.3.1.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces A closer view of \texttt  {Instance} in Figure \ref  {fig:forest_uml}.\relax }}{32}{figure.caption.32}}
\newlabel{fig:instance_uml}{{3.4}{32}{A closer view of \texttt {Instance} in Figure \ref {fig:forest_uml}.\relax }{figure.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Important methods implemented in the \texttt  {NDRealVector} class.\relax }}{33}{table.caption.33}}
\newlabel{tab:NDRealVector}{{3.2}{33}{Important methods implemented in the \texttt {NDRealVector} class.\relax }{table.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.3}Probability Distributions}{33}{subsubsection.3.1.1.3}}
\newlabel{sec:prob_dist}{{3.1.1.3}{33}{Probability Distributions}{subsubsection.3.1.1.3}{}}
\newlabel{eq:prob_entropy}{{3.1}{33}{Probability Distributions}{equation.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces A closer view of \texttt  {ProbabilityDistribution} in Figure \ref  {fig:forest_uml}.\relax }}{34}{figure.caption.34}}
\newlabel{fig:prob_dist_uml}{{3.5}{34}{A closer view of \texttt {ProbabilityDistribution} in Figure \ref {fig:forest_uml}.\relax }{figure.caption.34}{}}
\citation{1985--ieee754}
\newlabel{eq:sum}{{3.10}{35}{Probability Distributions}{equation.3.1.10}{}}
\newlabel{eq:numstabsum}{{3.11}{35}{Probability Distributions}{equation.3.1.11}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}The \texttt  {ProbabilityDistribution} constructor.}{36}{lstlisting.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Important methods implemented in \texttt  {ProbabilityDistribution}.}}{37}{table.caption.36}}
\newlabel{tab:ProbabilityDistribution}{{3.3}{37}{Important methods implemented in \texttt {ProbabilityDistribution}}{table.caption.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.4}Training Sequences}{37}{subsubsection.3.1.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces A closer view of \texttt  {TrainingSequence} and \texttt  {TrainingSample}}}{38}{figure.caption.37}}
\newlabel{fig:training_seq_uml}{{3.6}{38}{A closer view of \texttt {TrainingSequence} and \texttt {TrainingSample}}{figure.caption.37}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Important methods implemented in the \texttt  {TrainingSequence} class.\relax }}{39}{table.caption.38}}
\newlabel{tab:TrainingSequence}{{3.4}{39}{Important methods implemented in the \texttt {TrainingSequence} class.\relax }{table.caption.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.5}Split Parameters}{40}{subsubsection.3.1.1.5}}
\newlabel{sec:split_params}{{3.1.1.5}{40}{Split Parameters}{subsubsection.3.1.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces A closer view of \texttt  {SplitParamter}}}{41}{figure.caption.39}}
\newlabel{fig:split_param_uml}{{3.7}{41}{A closer view of \texttt {SplitParamter}}{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.6}Weak Learners}{41}{subsubsection.3.1.1.6}}
\newlabel{sec:weak_learner}{{3.1.1.6}{41}{Weak Learners}{subsubsection.3.1.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces A closer view of the \texttt  {WeakLearnerType} enum in Figure \ref  {fig:forest_uml}.\relax }}{42}{figure.caption.40}}
\newlabel{fig:weak_learner_type_uml}{{3.8}{42}{A closer view of the \texttt {WeakLearnerType} enum in Figure \ref {fig:forest_uml}.\relax }{figure.caption.40}{}}
\newlabel{eq:split_equation}{{3.12}{42}{Weak Learners}{equation.3.1.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces A closer view of \texttt  {WeakLearner} and \texttt  {DimensionalLinearWeakLearner}}}{43}{figure.caption.41}}
\newlabel{fig:weak_learner_uml}{{3.9}{43}{A closer view of \texttt {WeakLearner} and \texttt {DimensionalLinearWeakLearner}}{figure.caption.41}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces The methods of \texttt  {OneDimesnionalLinearWeakLearner}.}}{44}{table.caption.42}}
\newlabel{tab:OneDimensionalLinearWeakLearner}{{3.5}{44}{The methods of \texttt {OneDimesnionalLinearWeakLearner}}{table.caption.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.7}Decision Tree Node}{45}{subsubsection.3.1.1.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces A closer view of \texttt  {TreeNode} and \texttt  {DecisionForest} in Figure \ref  {fig:forest_uml}.\relax }}{46}{figure.caption.43}}
\newlabel{fig:weak_learner_uml}{{3.10}{46}{A closer view of \texttt {TreeNode} and \texttt {DecisionForest} in Figure \ref {fig:forest_uml}.\relax }{figure.caption.43}{}}
\newlabel{lst:TreeNode}{{3.2}{47}{The \texttt {TreeNode} declaration}{lstlisting.3.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}The \texttt  {TreeNode} declaration.}{47}{lstlisting.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Important methods implemented in the \texttt  {TreeNode} class.\relax }}{48}{table.caption.45}}
\newlabel{tab:TreeNode}{{3.6}{48}{Important methods implemented in the \texttt {TreeNode} class.\relax }{table.caption.45}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.8}Decision Forest}{48}{subsubsection.3.1.1.8}}
\newlabel{sec:DecisionForest}{{3.1.1.8}{48}{Decision Forest}{subsubsection.3.1.1.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Important methods implemented in the \texttt  {DecisionForest} class.\relax }}{49}{table.caption.46}}
\newlabel{tab:DecisionForest}{{3.7}{49}{Important methods implemented in the \texttt {DecisionForest} class.\relax }{table.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Training}{49}{subsection.3.1.2}}
\newlabel{sec:training}{{3.1.2}{49}{Training}{subsection.3.1.2}{}}
\newlabel{lst:generateTree}{{3.3}{50}{Psuedocode to train a decision tree}{lstlisting.3.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.3}Psuedocode to train a decision tree.}{50}{lstlisting.3.3}}
\citation{criminisi2013decision}
\citation{criminisi2013decision}
\citation{criminisi2013decision}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Visualisation of breadth first vs depth first.}}{52}{figure.caption.48}}
\newlabel{fig:breadth_first}{{3.11}{52}{Visualisation of breadth first vs depth first}{figure.caption.48}{}}
\newlabel{lst:train}{{3.4}{52}{Psuedocode to train a decision forest}{lstlisting.3.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.4}Psuedocode to train a decision forest.}{52}{lstlisting.3.4}}
\newlabel{lst:traverseTree}{{3.5}{53}{Psuedocode for traversing a decision tree}{lstlisting.3.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.5}Psuedocode for traversing a decision tree.}{53}{lstlisting.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Classification}{53}{subsection.3.1.3}}
\newlabel{sec:classification}{{3.1.3}{53}{Classification}{subsection.3.1.3}{}}
\newlabel{lst:classify}{{3.6}{54}{Psuedocode for classification using a decision tree}{lstlisting.3.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.6}Psuedocode for classification using a decision tree.}{54}{lstlisting.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Neural Networks}{54}{section.3.2}}
\newlabel{sec:nn_training}{{3.2}{54}{Neural Networks}{section.3.2}{}}
\newlabel{sec:pixel_label}{{3.2}{54}{Neural Networks}{section.3.2}{}}
\newlabel{eq:softmax_defn}{{3.13}{54}{Neural Networks}{equation.3.2.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces The UML diagram for the Neural Net package.\relax }}{55}{figure.caption.52}}
\newlabel{eq:activationinput}{{3.14}{55}{Neural Networks}{equation.3.2.14}{}}
\newlabel{lst:network_def}{{3.7}{55}{Simple construction of our neural network in Encog}{lstlisting.3.7}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.7}Simple construction of our neural network in Encog.}{55}{lstlisting.3.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces The architecture of our neural network for classification.\relax }}{56}{figure.caption.53}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces The UML diagram for the pixel labelling module.\relax }}{57}{figure.caption.54}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Pixel Labelling}{57}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training Tools}{59}{section.3.4}}
\newlabel{sec:training_tools}{{3.4}{59}{Training Tools}{section.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces The UML diagram for the training tools module.}}{59}{figure.caption.56}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces The four possible pixel labellings types we can output.}}{60}{figure.caption.55}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces An example input to the training tools module.}}{61}{figure.caption.57}}
\citation{picano2004sustainability}
\citation{sprawls1987physical}
\citation{coupe2009nonlocal}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Example of part of the output file from the training tools module}}{62}{figure.caption.58}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces An example of a noisy `ground truth' pixel labelling.}}{62}{figure.caption.59}}
\newlabel{fig:non_perfect_labelling}{{3.19}{62}{An example of a noisy `ground truth' pixel labelling}{figure.caption.59}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}De-noising}{62}{section.3.5}}
\newlabel{sec:de-noising}{{3.5}{62}{De-noising}{section.3.5}{}}
\citation{figueiredo2006total}
\citation{BoofCV2012}
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces The UML diagram for the Noise package.\relax }}{63}{figure.caption.60}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Application on example data sets}{63}{section.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Siri's data}{63}{subsection.3.6.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation}{65}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Performance measures for classifiers}{65}{section.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Evaluation of the Random Forests library}{65}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Training time}{66}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Classification time}{66}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}The effect of the number of trees}{66}{subsection.4.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}The effect of the depth of trees}{66}{subsection.4.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}The effect of the randomness of trees}{66}{subsection.4.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}The effect of normalisation}{66}{subsection.4.2.6}}
\newlabel{sec:effect_of_normalisation}{{4.2.6}{66}{The effect of normalisation}{subsection.4.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}The effect of the de-noising component}{66}{section.4.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{67}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Summary}{67}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Further Work}{67}{section.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Lessons Learned}{67}{section.5.3}}
\bibdata{refs}
\bibcite{1985--ieee754}{1}
\bibcite{badrinarayanan2015segnet2}{2}
\bibcite{Bioucas-Dias:2012:unmixingOverview}{3}
\bibcite{conjeti2016supervised}{4}
\bibcite{coupe2009nonlocal}{5}
\bibcite{criminisi2013decision}{6}
\bibcite{criminisi2012decision}{7}
\bibcite{cunningham2007k}{8}
\bibcite{figueiredo2006total}{9}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{69}{section.5.3}}
\bibcite{gamal2005cmos}{10}
\bibcite{hasinoff2014photon}{11}
\bibcite{heaton2008introduction}{12}
\bibcite{JMLR:v16:heaton15a}{13}
\bibcite{jia2014caffe}{14}
\bibcite{keshava2003survey}{15}
\bibcite{klein2004lagrange}{16}
\bibcite{law2006simple}{17}
\bibcite{Qingli:2013:spectralImagingTech}{18}
\bibcite{Luthman:2015:hyperspectralImager}{19}
\bibcite{PAL19931277}{20}
\bibcite{pham2000current}{21}
\bibcite{picano2004sustainability}{22}
\bibcite{rodrigues2008denoising}{23}
\bibcite{ross2002probability}{24}
\bibcite{russell1995modern}{25}
\bibcite{seymore1999learning}{26}
\bibcite{sprawls1987physical}{27}
\bibcite{zhao2016segmenting}{28}
\bibcite{zhao2016multiscale}{29}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}File formats}{73}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:file_formats}{{A}{73}{File formats}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Example Spectral Image}{73}{section.A.1}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Example Image Labelling}{73}{section.A.2}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Label Map}{73}{section.A.3}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Training Sequence}{73}{section.A.4}}
\@writefile{toc}{\contentsline {section}{\numberline {A.5}Output Files}{74}{section.A.5}}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Imaging and image noise}{75}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:img_noise}{{B}{75}{Imaging and image noise}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Image sensor arrays}{75}{section.B.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces CCD and CMOS sensor arrays.}}{75}{figure.caption.64}}
\newlabel{fig:image_pipeline}{{B.1}{75}{CCD and CMOS sensor arrays}{figure.caption.64}{}}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\citation{gamal2005cmos}
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Overview of an imaging `pipeline'.}}{76}{figure.caption.65}}
\newlabel{fig:image_pipeline}{{B.2}{76}{Overview of an imaging `pipeline'}{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.3}{\ignorespaces Parallel stream of photons incident on one sensor in a sensor array.\relax }}{76}{figure.caption.66}}
\newlabel{fig:photon_stream}{{B.3}{76}{Parallel stream of photons incident on one sensor in a sensor array.\relax }{figure.caption.66}{}}
\citation{hasinoff2014photon}
\citation{ross2002probability}
\@writefile{lof}{\contentsline {figure}{\numberline {B.4}{\ignorespaces The charge held on a capacitor is linear with respect time, until it hits some maximum \cite  {gamal2005cmos}.\relax }}{77}{figure.caption.67}}
\newlabel{fig:linear_charge_wrt_photon_rate}{{B.4}{77}{The charge held on a capacitor is linear with respect time, until it hits some maximum \cite {gamal2005cmos}.\relax }{figure.caption.67}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Quantum noise}{77}{section.B.2}}
\newlabel{sec:quantum_noise}{{B.2}{77}{Quantum noise}{section.B.2}{}}
\newlabel{eq:image_poisson}{{B.2}{77}{Quantum noise}{equation.B.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.5}{\ignorespaces Example of Poisson($\mu $) and SPoisson($\mu $, 30) distributions.}}{79}{figure.caption.68}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Additive White Gaussian Noise}{79}{section.B.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Code for training a decision forest}{81}{appendix.C}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:train_tree}{{C}{81}{Code for training a decision forest}{appendix.C}{}}
\newlabel{lst:actualGenerateTree}{{C.1}{81}{The implementation code for tree generation}{lstlisting.C.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {C.1}The implementation code for tree generation.}{81}{lstlisting.C.1}}
\newlabel{lst:actualTrainForest}{{C.2}{83}{The implementation code for training a decision forest}{lstlisting.C.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {C.2}The implementation code for training a decision forest.}{83}{lstlisting.C.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Code for classifying using a decision forest}{87}{appendix.D}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:classify_tree}{{D}{87}{Code for classifying using a decision forest}{appendix.D}{}}
\newlabel{lst:actualTraverseTree}{{D.1}{87}{The implementation code for tree traversal}{lstlisting.D.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {D.1}The implementation code for tree traversal.}{87}{lstlisting.D.1}}
\newlabel{lst:actualTraverseTree}{{D.2}{88}{The implementation code for classification using a decision forest}{lstlisting.D.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {D.2}The implementation code for classification using a decision forest.}{88}{lstlisting.D.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {E}Project Proposal}{91}{appendix.E}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {F}Glossary}{103}{appendix.F}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
